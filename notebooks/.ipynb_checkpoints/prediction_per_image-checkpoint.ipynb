{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torchnet as tnt\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_weight_file=None):\n",
    "################### test started#########################\n",
    "    phase='test'\n",
    "    running_corrects = 0\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(3)\n",
    "    # Iterate over data.\n",
    "    for data in tqdm(dataloaders[phase]):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        confusion_matrix.add(outputs.data.squeeze(),\n",
    "                             labels.type(torch.LongTensor))\n",
    "\n",
    "    epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "    print('evaluation statistics')\n",
    "    print('{} Acc: {:.4f}'.format(\n",
    "        phase, epoch_acc))\n",
    "    conf = confusion_matrix.value()\n",
    "    print('class average precision: ' + str(\n",
    "        np.sum(np.diagonal(conf / conf.sum(1).clip(min=1e-2))) / len(class_names)))\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(conf)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                      shuffle=False, num_workers=8)\n",
    "       for x in ['test']}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['test']}\n",
    "class_names = image_datasets['test'].classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_file = '../torch/vgg19_model_for_real.pth'\n",
    "\n",
    "model_ft = models.vgg19(pretrained=False)\n",
    "classifier = list(model_ft.classifier)\n",
    "classifier.pop()\n",
    "classifier.append(nn.Linear(classifier[3].out_features, 3))\n",
    "model_ft.classifier = nn.Sequential(*classifier)\n",
    "model_ft.train(False)  # Set model to evaluate mode\n",
    "model_ft.load_state_dict(torch.load(model_weight_file), strict=True)\n",
    "model_ft = model_ft.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1229/1229 [02:09<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation statistics\n",
      "test Acc: 0.9422\n",
      "class average precision: 0.816901371867116\n",
      "Confusion Matrix\n",
      "\n",
      "[[  528   253   176]\n",
      " [  244 12936    16]\n",
      " [  396    51  5050]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model_ft, model_weight_file=model_weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = data_transforms['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "#     with open(path, 'rb') as f:\n",
    "#         img = Image.open(f)\n",
    "    img = Image.open(path)\n",
    "    return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['files'] = glob('../test/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_true']=df.files.apply(lambda x: x.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_ft,path):\n",
    "    img = pil_loader(path)\n",
    "    transformed_sample = trans(img)\n",
    "    inputs = torch.autograd.Variable(torch.unsqueeze(transformed_sample,0))\n",
    "    output = model_ft(inputs.cuda())\n",
    "    _, preds = torch.max(output.data,1)\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_pred']=df.files.apply(lambda x: predict(model_ft,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../test/2/24b_d4.1_1-2_414_160.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../test/2/5_c4.1_2-2_394_58.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../test/2/5_c4.2_0-2_439_80.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../test/2/5_c6.1_2-2_311_190.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../test/2/5_c4.1_2-2_221_382.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                files y_true  y_pred\n",
       "0  ../test/2/24b_d4.1_1-2_414_160.jpg      2       2\n",
       "1     ../test/2/5_c4.1_2-2_394_58.jpg      2       2\n",
       "2     ../test/2/5_c4.2_0-2_439_80.jpg      2       2\n",
       "3    ../test/2/5_c6.1_2-2_311_190.jpg      2       2\n",
       "4    ../test/2/5_c4.1_2-2_221_382.jpg      2       2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
